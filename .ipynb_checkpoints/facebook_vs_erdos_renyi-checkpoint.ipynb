{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbf00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Facebook vs Erdős-Rényi Network Comparison\n",
    "==========================================\n",
    "\n",
    "Direct comparison between the full Facebook social network and an equivalent \n",
    "Erdős-Rényi random graph with the same number of nodes and edges.\n",
    "\n",
    "This analysis demonstrates why random graphs fail to capture the structure\n",
    "of real-world social networks.\n",
    "\n",
    "Author: Network Analysis Course\n",
    "Date: 2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b131e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f681d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b9406",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FacebookERComparison:\n",
    "    \"\"\"Compare Facebook network with equivalent Erdős-Rényi graph.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=\"datasets\"):\n",
    "        \"\"\"Initialize the comparison.\"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.facebook_graph = None\n",
    "        self.er_graph = None\n",
    "        self.analysis_results = {}\n",
    "        \n",
    "    def load_facebook_network(self, filename=\"facebook_combined.txt.gz\"):\n",
    "        \"\"\"Load the full Facebook social network.\"\"\"\n",
    "        filepath = os.path.join(self.data_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Error: {filepath} not found!\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"Loading Facebook network from {filename}...\")\n",
    "        \n",
    "        # Load the network\n",
    "        self.facebook_graph = nx.Graph()\n",
    "        \n",
    "        with gzip.open(filepath, 'rt') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    u, v = map(int, line.strip().split())\n",
    "                    self.facebook_graph.add_edge(u, v)\n",
    "        \n",
    "        print(f\"✓ Loaded Facebook network:\")\n",
    "        print(f\"  • {self.facebook_graph.number_of_nodes():,} nodes\")\n",
    "        print(f\"  • {self.facebook_graph.number_of_edges():,} edges\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_equivalent_er_graph(self):\n",
    "        \"\"\"Generate Erdős-Rényi graph with same nodes and expected edges.\"\"\"\n",
    "        if self.facebook_graph is None:\n",
    "            print(\"Please load Facebook network first!\")\n",
    "            return False\n",
    "        \n",
    "        n = self.facebook_graph.number_of_nodes()\n",
    "        m = self.facebook_graph.number_of_edges()\n",
    "        \n",
    "        # Calculate probability for same expected number of edges\n",
    "        p = (2 * m) / (n * (n - 1))\n",
    "        \n",
    "        print(f\"\\nGenerating equivalent Erdős-Rényi graph...\")\n",
    "        print(f\"  • Nodes: {n:,}\")\n",
    "        print(f\"  • Target edges: {m:,}\")\n",
    "        print(f\"  • Connection probability: {p:.6f}\")\n",
    "        \n",
    "        # Generate ER graph\n",
    "        self.er_graph = nx.erdos_renyi_graph(n, p, seed=42)\n",
    "        \n",
    "        print(f\"✓ Generated ER graph:\")\n",
    "        print(f\"  • {self.er_graph.number_of_nodes():,} nodes\")\n",
    "        print(f\"  • {self.er_graph.number_of_edges():,} edges\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def analyze_network_properties(self):\n",
    "        \"\"\"Analyze and compare key network properties.\"\"\"\n",
    "        if self.facebook_graph is None or self.er_graph is None:\n",
    "            print(\"Please load networks first!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"COMPREHENSIVE NETWORK ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        networks = {\n",
    "            'Facebook': self.facebook_graph,\n",
    "            'Erdős-Rényi': self.er_graph\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, G in networks.items():\n",
    "            print(f\"\\nAnalyzing {name} network...\")\n",
    "            \n",
    "            stats = {}\n",
    "            \n",
    "            # Basic properties\n",
    "            stats['nodes'] = G.number_of_nodes()\n",
    "            stats['edges'] = G.number_of_edges()\n",
    "            stats['density'] = nx.density(G)\n",
    "            \n",
    "            # Degree statistics\n",
    "            degrees = [d for n, d in G.degree()]\n",
    "            stats['avg_degree'] = np.mean(degrees)\n",
    "            stats['median_degree'] = np.median(degrees)\n",
    "            stats['max_degree'] = max(degrees)\n",
    "            stats['min_degree'] = min(degrees)\n",
    "            stats['degree_std'] = np.std(degrees)\n",
    "            stats['degree_variance'] = np.var(degrees)\n",
    "            \n",
    "            # Connectivity analysis\n",
    "            stats['is_connected'] = nx.is_connected(G)\n",
    "            stats['num_components'] = nx.number_connected_components(G)\n",
    "            \n",
    "            # Work with largest component for path analysis\n",
    "            if stats['is_connected']:\n",
    "                largest_cc = G\n",
    "                stats['largest_component_size'] = stats['nodes']\n",
    "                stats['largest_component_fraction'] = 1.0\n",
    "            else:\n",
    "                largest_cc_nodes = max(nx.connected_components(G), key=len)\n",
    "                largest_cc = G.subgraph(largest_cc_nodes)\n",
    "                stats['largest_component_size'] = largest_cc.number_of_nodes()\n",
    "                stats['largest_component_fraction'] = stats['largest_component_size'] / stats['nodes']\n",
    "            \n",
    "            # Path lengths (on largest component)\n",
    "            if largest_cc.number_of_nodes() > 1:\n",
    "                print(f\"  Computing path lengths on component with {largest_cc.number_of_nodes():,} nodes...\")\n",
    "                stats['avg_path_length'] = nx.average_shortest_path_length(largest_cc)\n",
    "                stats['diameter'] = nx.diameter(largest_cc)\n",
    "            else:\n",
    "                stats['avg_path_length'] = 0\n",
    "                stats['diameter'] = 0\n",
    "            \n",
    "            # Clustering analysis\n",
    "            print(f\"  Computing clustering coefficients...\")\n",
    "            stats['avg_clustering'] = nx.average_clustering(G)\n",
    "            stats['global_clustering'] = nx.transitivity(G)\n",
    "            \n",
    "            # Degree distribution analysis\n",
    "            degree_counts = Counter(degrees)\n",
    "            stats['degree_distribution'] = degree_counts\n",
    "            stats['unique_degrees'] = len(degree_counts)\n",
    "            \n",
    "            results[name] = stats\n",
    "        \n",
    "        self.analysis_results = results\n",
    "        \n",
    "        # Print comparison table\n",
    "        self.print_comparison_table()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_comparison_table(self):\n",
    "        \"\"\"Print detailed comparison table.\"\"\"\n",
    "        if not self.analysis_results:\n",
    "            return\n",
    "        \n",
    "        fb_stats = self.analysis_results['Facebook']\n",
    "        er_stats = self.analysis_results['Erdős-Rényi']\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"DETAILED COMPARISON TABLE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"{'Property':<25} {'Facebook':<15} {'Erdős-Rényi':<15} {'Ratio (FB/ER)':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Basic properties\n",
    "        print(f\"{'Nodes':<25} {fb_stats['nodes']:<15,} {er_stats['nodes']:<15,} {fb_stats['nodes']/er_stats['nodes']:<15.2f}\")\n",
    "        print(f\"{'Edges':<25} {fb_stats['edges']:<15,} {er_stats['edges']:<15,} {fb_stats['edges']/er_stats['edges']:<15.2f}\")\n",
    "        print(f\"{'Density':<25} {fb_stats['density']:<15.6f} {er_stats['density']:<15.6f} {fb_stats['density']/er_stats['density']:<15.2f}\")\n",
    "        \n",
    "        print()\n",
    "        # Degree statistics\n",
    "        print(f\"{'Average Degree':<25} {fb_stats['avg_degree']:<15.2f} {er_stats['avg_degree']:<15.2f} {fb_stats['avg_degree']/er_stats['avg_degree']:<15.2f}\")\n",
    "        print(f\"{'Median Degree':<25} {fb_stats['median_degree']:<15.2f} {er_stats['median_degree']:<15.2f} {fb_stats['median_degree']/er_stats['median_degree']:<15.2f}\")\n",
    "        print(f\"{'Max Degree':<25} {fb_stats['max_degree']:<15} {er_stats['max_degree']:<15} {fb_stats['max_degree']/er_stats['max_degree']:<15.2f}\")\n",
    "        print(f\"{'Degree Std Dev':<25} {fb_stats['degree_std']:<15.2f} {er_stats['degree_std']:<15.2f} {fb_stats['degree_std']/er_stats['degree_std']:<15.2f}\")\n",
    "        \n",
    "        print()\n",
    "        # Connectivity\n",
    "        print(f\"{'Is Connected':<25} {str(fb_stats['is_connected']):<15} {str(er_stats['is_connected']):<15} {'-':<15}\")\n",
    "        print(f\"{'Num Components':<25} {fb_stats['num_components']:<15} {er_stats['num_components']:<15} {fb_stats['num_components']/er_stats['num_components']:<15.2f}\")\n",
    "        print(f\"{'Largest Comp %':<25} {fb_stats['largest_component_fraction']*100:<15.1f} {er_stats['largest_component_fraction']*100:<15.1f} {fb_stats['largest_component_fraction']/er_stats['largest_component_fraction']:<15.2f}\")\n",
    "        \n",
    "        print()\n",
    "        # Path lengths\n",
    "        if fb_stats['avg_path_length'] > 0 and er_stats['avg_path_length'] > 0:\n",
    "            print(f\"{'Avg Path Length':<25} {fb_stats['avg_path_length']:<15.2f} {er_stats['avg_path_length']:<15.2f} {fb_stats['avg_path_length']/er_stats['avg_path_length']:<15.2f}\")\n",
    "            print(f\"{'Diameter':<25} {fb_stats['diameter']:<15} {er_stats['diameter']:<15} {fb_stats['diameter']/er_stats['diameter']:<15.2f}\")\n",
    "        \n",
    "        print()\n",
    "        # Clustering\n",
    "        print(f\"{'Avg Clustering':<25} {fb_stats['avg_clustering']:<15.4f} {er_stats['avg_clustering']:<15.4f} {fb_stats['avg_clustering']/er_stats['avg_clustering']:<15.1f}\")\n",
    "        print(f\"{'Global Clustering':<25} {fb_stats['global_clustering']:<15.4f} {er_stats['global_clustering']:<15.4f} {fb_stats['global_clustering']/er_stats['global_clustering']:<15.1f}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"KEY INSIGHTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        clustering_ratio = fb_stats['avg_clustering'] / er_stats['avg_clustering']\n",
    "        degree_var_ratio = fb_stats['degree_variance'] / er_stats['degree_variance']\n",
    "        \n",
    "        print(f\"• Facebook clustering is {clustering_ratio:.1f}x higher than ER\")\n",
    "        print(f\"• Facebook degree variance is {degree_var_ratio:.1f}x higher than ER\")\n",
    "        print(f\"• Facebook has {fb_stats['max_degree']} max degree vs {er_stats['max_degree']} for ER\")\n",
    "        print(f\"• This demonstrates the limitations of random graph models for social networks\")\n",
    "        \n",
    "        if not fb_stats['is_connected'] and er_stats['is_connected']:\n",
    "            print(f\"• Facebook is fragmented ({fb_stats['num_components']} components) while ER is connected\")\n",
    "        elif fb_stats['is_connected'] and not er_stats['is_connected']:\n",
    "            print(f\"• Facebook is connected while ER is fragmented ({er_stats['num_components']} components)\")\n",
    "    \n",
    "    def create_comprehensive_comparison_plot(self):\n",
    "        \"\"\"Create comprehensive comparison visualizations.\"\"\"\n",
    "        if not self.analysis_results:\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "        fig.suptitle('Facebook vs Erdős-Rényi: Comprehensive Comparison', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        fb_graph = self.facebook_graph\n",
    "        er_graph = self.er_graph\n",
    "        \n",
    "        # 1. Degree Distribution Comparison\n",
    "        ax = axes[0, 0]\n",
    "        \n",
    "        fb_degrees = [d for n, d in fb_graph.degree()]\n",
    "        er_degrees = [d for n, d in er_graph.degree()]\n",
    "        \n",
    "        ax.hist(fb_degrees, bins=50, alpha=0.7, label='Facebook', color='blue', density=True)\n",
    "        ax.hist(er_degrees, bins=50, alpha=0.7, label='Erdős-Rényi', color='red', density=True)\n",
    "        \n",
    "        ax.set_xlabel('Degree')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title('Degree Distribution Comparison')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        ax.axvline(np.mean(fb_degrees), color='blue', linestyle='--', alpha=0.8)\n",
    "        ax.axvline(np.mean(er_degrees), color='red', linestyle='--', alpha=0.8)\n",
    "        \n",
    "        # 2. Log-Log Degree Distribution\n",
    "        ax = axes[0, 1]\n",
    "        \n",
    "        fb_degree_counts = Counter(fb_degrees)\n",
    "        er_degree_counts = Counter(er_degrees)\n",
    "        \n",
    "        fb_degrees_unique = sorted(fb_degree_counts.keys())\n",
    "        fb_counts = [fb_degree_counts[d] for d in fb_degrees_unique]\n",
    "        \n",
    "        er_degrees_unique = sorted(er_degree_counts.keys())\n",
    "        er_counts = [er_degree_counts[d] for d in er_degrees_unique]\n",
    "        \n",
    "        ax.loglog(fb_degrees_unique, fb_counts, 'bo-', alpha=0.7, markersize=3, label='Facebook')\n",
    "        ax.loglog(er_degrees_unique, er_counts, 'ro-', alpha=0.7, markersize=3, label='Erdős-Rényi')\n",
    "        \n",
    "        ax.set_xlabel('Degree (log scale)')\n",
    "        ax.set_ylabel('Frequency (log scale)')\n",
    "        ax.set_title('Degree Distribution (Log-Log)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Clustering Coefficient Distribution\n",
    "        ax = axes[1, 0]\n",
    "        \n",
    "        fb_clustering = list(nx.clustering(fb_graph).values())\n",
    "        er_clustering = list(nx.clustering(er_graph).values())\n",
    "        \n",
    "        ax.hist(fb_clustering, bins=30, alpha=0.7, label='Facebook', color='blue', density=True)\n",
    "        ax.hist(er_clustering, bins=30, alpha=0.7, label='Erdős-Rényi', color='red', density=True)\n",
    "        \n",
    "        ax.set_xlabel('Local Clustering Coefficient')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title('Clustering Coefficient Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Degree vs Clustering\n",
    "        ax = axes[1, 1]\n",
    "        \n",
    "        # Sample for visualization if needed\n",
    "        sample_size = min(2000, fb_graph.number_of_nodes())\n",
    "        fb_nodes_sample = np.random.choice(list(fb_graph.nodes()), sample_size, replace=False)\n",
    "        er_nodes_sample = np.random.choice(list(er_graph.nodes()), sample_size, replace=False)\n",
    "        \n",
    "        fb_degrees_sample = [fb_graph.degree(n) for n in fb_nodes_sample]\n",
    "        fb_clustering_sample = [nx.clustering(fb_graph, n) for n in fb_nodes_sample]\n",
    "        \n",
    "        er_degrees_sample = [er_graph.degree(n) for n in er_nodes_sample]\n",
    "        er_clustering_sample = [nx.clustering(er_graph, n) for n in er_nodes_sample]\n",
    "        \n",
    "        ax.scatter(fb_degrees_sample, fb_clustering_sample, alpha=0.5, s=10, \n",
    "                  color='blue', label='Facebook')\n",
    "        ax.scatter(er_degrees_sample, er_clustering_sample, alpha=0.5, s=10, \n",
    "                  color='red', label='Erdős-Rényi')\n",
    "        \n",
    "        ax.set_xlabel('Node Degree')\n",
    "        ax.set_ylabel('Local Clustering Coefficient')\n",
    "        ax.set_title('Degree vs Local Clustering')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Network Properties Bar Chart\n",
    "        ax = axes[2, 0]\n",
    "        \n",
    "        properties = ['Avg Clustering', 'Global Clustering', 'Avg Degree', 'Max Degree/100']\n",
    "        fb_values = [\n",
    "            self.analysis_results['Facebook']['avg_clustering'],\n",
    "            self.analysis_results['Facebook']['global_clustering'],\n",
    "            self.analysis_results['Facebook']['avg_degree'],\n",
    "            self.analysis_results['Facebook']['max_degree'] / 100\n",
    "        ]\n",
    "        er_values = [\n",
    "            self.analysis_results['Erdős-Rényi']['avg_clustering'],\n",
    "            self.analysis_results['Erdős-Rényi']['global_clustering'],\n",
    "            self.analysis_results['Erdős-Rényi']['avg_degree'],\n",
    "            self.analysis_results['Erdős-Rényi']['max_degree'] / 100\n",
    "        ]\n",
    "        \n",
    "        x = np.arange(len(properties))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, fb_values, width, label='Facebook', color='blue', alpha=0.7)\n",
    "        ax.bar(x + width/2, er_values, width, label='Erdős-Rényi', color='red', alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Network Properties')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_title('Network Properties Comparison')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(properties, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Component Size Distribution\n",
    "        ax = axes[2, 1]\n",
    "        \n",
    "        fb_components = [len(c) for c in nx.connected_components(fb_graph)]\n",
    "        er_components = [len(c) for c in nx.connected_components(er_graph)]\n",
    "        \n",
    "        fb_components.sort(reverse=True)\n",
    "        er_components.sort(reverse=True)\n",
    "        \n",
    "        # Show top 20 components\n",
    "        fb_top = fb_components[:20] if len(fb_components) > 20 else fb_components\n",
    "        er_top = er_components[:20] if len(er_components) > 20 else er_components\n",
    "        \n",
    "        ax.semilogy(range(1, len(fb_top) + 1), fb_top, 'bo-', label='Facebook', markersize=4)\n",
    "        ax.semilogy(range(1, len(er_top) + 1), er_top, 'ro-', label='Erdős-Rényi', markersize=4)\n",
    "        \n",
    "        ax.set_xlabel('Component Rank')\n",
    "        ax.set_ylabel('Component Size (log scale)')\n",
    "        ax.set_title('Component Size Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('facebook_vs_erdos_renyi_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\nComprehensive comparison plot saved as 'facebook_vs_erdos_renyi_comparison.png'\")\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f3ad0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run Facebook vs ER comparison.\"\"\"\n",
    "    print(\"Facebook vs Erdős-Rényi Network Comparison\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize comparison\n",
    "    comparison = FacebookERComparison()\n",
    "    \n",
    "    # Load Facebook network\n",
    "    if not comparison.load_facebook_network():\n",
    "        print(\"Failed to load Facebook network. Please check the data file.\")\n",
    "        return\n",
    "    \n",
    "    # Generate equivalent ER graph\n",
    "    if not comparison.generate_equivalent_er_graph():\n",
    "        print(\"Failed to generate ER graph.\")\n",
    "        return\n",
    "    \n",
    "    # Analyze and compare properties\n",
    "    comparison.analyze_network_properties()\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    comparison.create_comprehensive_comparison_plot()\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Generated file: facebook_vs_erdos_renyi_comparison.png\")\n",
    "    print(\"\\nThis analysis clearly demonstrates why Erdős-Rényi graphs\")\n",
    "    print(\"fail to capture the structural properties of real social networks:\")\n",
    "    print(\"  • Much lower clustering in ER graphs\")\n",
    "    print(\"  • Different degree distributions\")\n",
    "    print(\"  • Different connectivity patterns\")\n",
    "    print(\"  • Missing community structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda56a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
